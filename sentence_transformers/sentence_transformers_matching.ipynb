{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "banner-richardson",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import pickle5 as pickle\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "interesting-dividend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data\n",
    "df_targets = pd.read_csv('../data/processed/taxonomy_final_targets.csv')\n",
    "df_columns = df_targets.drop(columns=['PIMS_ID', 'all_text', 'all_text_clean', 'all_text_clean_spacy',  'hyperlink',\n",
    " 'title',\n",
    " 'leading_country',\n",
    " 'grant_amount',\n",
    " 'country_code',\n",
    " 'lon',\n",
    " 'lat'])\n",
    "    \n",
    "to_match_targets = df_columns.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "danish-audit",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer('paraphrase-distilroberta-base-v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "eleven-paris",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(to_match_targets)):\n",
    "    to_match_targets[i] = to_match_targets[i].replace('_', ' ')\n",
    "for i in range(len(transformed_cats)):\n",
    "    to_match_targets[i] = to_match_targets[i].lstrip()\n",
    "    \n",
    "original  = df_columns.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "packed-march",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compute embeddings\n",
    "corpus_embeddings = embedder.encode(to_match_targets, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "experienced-robin",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mangroves\n",
      "___________________________\n",
      "mangroves (Score: 1.0000)\n",
      "marshes (Score: 0.3959)\n",
      "rivers_and_river_basins (Score: 0.3544)\n",
      "savannas (Score: 0.3505)\n",
      "coral_reefs (Score: 0.3309)\n",
      "grazing_lands (Score: 0.3282)\n",
      "swamps (Score: 0.3279)\n",
      "_mercury (Score: 0.3235)\n",
      "boreal_forests_taiga_forests (Score: 0.3038)\n",
      "aquifers (Score: 0.2914)\n",
      "agriculture (Score: 0.2912)\n",
      "rift_valley (Score: 0.2886)\n",
      "clearing_house_mechanism (Score: 0.2734)\n",
      "deserts (Score: 0.2721)\n",
      "laws_enforcement_regulation (Score: 0.2687)\n",
      "mitigation_adaptation (Score: 0.2625)\n",
      "estuaries (Score: 0.2589)\n",
      "freshwaters (Score: 0.2576)\n",
      "transportation (Score: 0.2524)\n",
      "normative_support (Score: 0.2497)\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "print('___________________________')\n",
    "hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=20)\n",
    "hits = hits[0] #Get the hits for the first query\n",
    "matches = []\n",
    "for hit in hits:\n",
    "    matches.append(original[hit['corpus_id']])\n",
    "    print(original[hit['corpus_id']], \"(Score: {:.4f})\".format(hit['score']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
