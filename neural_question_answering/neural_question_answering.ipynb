{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import torch\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", use_fast=False)\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(\"bert-large-uncased-whole-word-masking-finetuned-squad\", return_dict=False)\n",
    "\n",
    "bi_encoder = SentenceTransformer('nq-distilbert-base-v1')\n",
    "\n",
    "from inspect import getsourcefile\n",
    "import os.path as path, sys\n",
    "current_dir = path.dirname(path.abspath(getsourcefile(lambda:0)))\n",
    "sys.path.insert(0, current_dir[:current_dir.rfind(path.sep)])\n",
    "import src.clean_dataset as clean\n",
    "\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1344\n"
     ]
    }
   ],
   "source": [
    "#import data:\n",
    "df = pd.read_csv('../data/processed/taxonomy_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69022330c4aa48fab5c3a2b23e3eef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/445 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitted = clean.split_at_length(df, 'all_text', 512)\n",
    "passages = splitted.text.tolist()\n",
    "corpus_embeddings = bi_encoder.encode(passages, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle5 as pickle\n",
    "pickle.dump(corpus_embeddings, open(\"../data/processed/splitted_corpus_embeddings.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11621\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14987c559b8440a9b08aa9011a905c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/364 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "splitted = clean.split_at_length(df, 'all_text', 1000)\n",
    "passages_long = splitted.text.tolist()\n",
    "print(len(passages_long))\n",
    "corpus_embeddings_long = bi_encoder.encode(passages_long, convert_to_tensor=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is done for LED lightning in Viet nam?\n",
      "Input question: what is done for LED lightning in Viet nam?\n",
      "Results (after 0.250 seconds):\n",
      "\t0.515\tThe project will expand the existing PA system through the establishment of one new terrestrial PA and two new marine PAs (the first marine PAs in the country).  In addition\n",
      "\t0.480\tthe project will address systemic issues by implementing key elements of SKNs Protected Areas System Plan\n",
      "\t0.477\tand EE. It will also include RE mini-grid how-to handbooks tailored to PNG\n",
      "\t0.473\tincluding the establishment of a centralized agency for protected areas management\n",
      "\t0.406\tficing for renewable energy and energy efficiency initiatives in the energy\n",
      "\n",
      "\n",
      "========\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = input()\n",
    "\n",
    "top_k = 5  # Number of passages we want to retrieve with the bi-encoder\n",
    "start_time = time.time()\n",
    "question_embedding = bi_encoder.encode(query, convert_to_tensor=True)\n",
    "hits = util.semantic_search(question_embedding, corpus_embeddings, top_k=top_k)\n",
    "hits = hits[0]  # Get the hits for the first query\n",
    "end_time = time.time()\n",
    "\n",
    "# Output of top-k hits\n",
    "print(\"Input question:\", query)\n",
    "print(\"Results (after {:.3f} seconds):\".format(end_time - start_time))\n",
    "matches = []\n",
    "for hit in hits:\n",
    "    print(\"\\t{:.3f}\\t{}\".format(hit['score'], passages[hit['corpus_id']]))\n",
    "    matches.append(passages[hit['corpus_id']])\n",
    "print(\"\\n\\n========\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The objective of the Project is to mitigate GHG emissions through transformation of the lighting market towards greater usage of locally produced LED lighting products in Viet Nam. This objective will be achieved by removing barriers to increased production and utilization of locally produced LED lighting products in Vietnam through two components: i) the transfer of skills'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is done for LED  lightning in Vietnam?\n",
      "Answer: removing barriers to increased production and utilization of locally produced led lighting products\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode_plus(query, matches[0], add_special_tokens=True, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
    "\n",
    "text_tokens = tokenizer.convert_ids_to_tokens(input_ids)\n",
    "answer_start_scores, answer_end_scores = model(**inputs)\n",
    "\n",
    "answer_start = torch.argmax(answer_start_scores)  # Get the most likely beginning of answer with the argmax of the score\n",
    "answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
    "\n",
    "print(f\"Question: {query}\")\n",
    "print(f\"Answer: {answer}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
